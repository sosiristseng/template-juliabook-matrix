name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}
  TIMEOUT: 600

jobs:
  docker:
    runs-on: ubuntu-latest
    steps:
      - uses: docker/setup-buildx-action@v2
      - name: Build and cache Docker Image
        uses: docker/build-push-action@v3
        with:
          file: .ci/Dockerfile
          tags: ${{ env.IMAGE_NAME }}:test
          outputs: type=docker,dest=/tmp/myimage.tar
          cache-from: type=gha
          cache-to: type=gha,mode=max
      - name: Cache Docker image
        uses: actions/cache@v3
        with:
          path: /tmp/myimage.tar
          key: ${{ runner.os }}-${{ github.sha }}

  execute:
    needs: docker
    strategy:
      fail-fast: false
      matrix:
        # Notebooks need to be executed
        notebook:
          - plots
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      - name: Restore Docker image
        uses: actions/cache@v3
        with:
          path: /tmp/myimage.tar
          key: ${{ runner.os }}-${{ github.sha }}
      - name: Load Docker Image
        run: docker load --input /tmp/myimage.tar
      - name: Execute Notebook
        run: >
          docker run
          -v ${{ github.workspace }}:/work
          -e JULIA_NUM_THREADS=auto
          ${{ env.IMAGE_NAME }}:test
          jupyter nbconvert --to notebook --ExecutePreprocessor.timeout=${{ env.TIMEOUT }} --execute --inplace
          /work/docs/${{ matrix.notebook }}.ipynb
      - name: Upload Notebook
        uses: actions/upload-artifact@v3
        with:
          name: ${{ matrix.notebook }}
          path: docs/${{ matrix.notebook }}.ipynb

  jupyter-book:
    needs: execute
    runs-on: ubuntu-latest
    # store success output flag for the ci job
    outputs:
      success: ${{ steps.setoutput.outputs.success }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.x'
      - run: pip install jupyter-book
      - name: Download notebooks
        uses: actions/download-artifact@v3
        with:
          path: out/
      - name: Move notebooks
        run: find out/ -type f -iname '*.ipynb' -exec mv -t docs/ {} +
      - name: Build website
        run: jupyter-book build docs/ -W -v
      - name: Set output flag
        id: setoutput
        run: echo "success=true" >> $GITHUB_OUTPUT
      - name: Setup Pages
        id: pages
        uses: actions/configure-pages@v2
      - name: Upload page artifact
        uses: actions/upload-pages-artifact@v1
        with:
          path: docs/_build/html

  # This job is for GitHub status check
  # https://brunoscheufler.com/blog/2022-04-09-the-required-github-status-check-that-wasnt
  ci:
    needs: [execute, jupyter-book]
    runs-on: ubuntu-latest
    if: always() # always run, so we never skip the check
    steps:
      # pass step only when output of previous jupyter-book job is set
      # in case at least one of the execution fails, jupyter-book is skipped
      # and the output will not be set, which will then cause the ci job to fail
      - run: |
          passed="${{ needs.jupyter-book.outputs.success }}"
          if [[ $passed == "true" ]]; then
            echo "Tests passed"
            exit 0
          else
            echo "Tests failed"
            exit 1
          fi

  # Deployment job
  deploy:
    needs: jupyter-book
    if: github.ref == 'refs/heads/main'
    # Grant GITHUB_TOKEN the permissions required to make a Pages deployment
    permissions:
      pages: write # to deploy to Pages
      id-token: write # to verify the deployment originates from an appropriate source
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v1
